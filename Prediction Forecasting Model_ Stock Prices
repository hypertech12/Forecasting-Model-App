{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO77tF5S372oOrJNFmptobK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"CHhtcbQov_ZX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741832002209,"user_tz":420,"elapsed":199,"user":{"displayName":"Rohit Chivukula","userId":"05375984481557127140"}},"outputId":"b82d600b-b825-4d27-c72b-857c3e3c11ff"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed"]},{"output_type":"stream","name":"stdout","text":["\n","Preview of predictions:\n","                  Close  Prediction_A  Prediction_B\n","Date                                               \n","2024-01-02  4742.830078   4789.946695   4786.362711\n","2024-01-03  4704.810059   4691.799913   4804.653477\n","2024-01-04  4688.680176   4749.416264   4737.089170\n","2024-01-05  4697.240234   4840.320977   4625.871777\n","2024-01-08  4763.540039   4741.232060   4740.473355\n","\n","Group Sizes:\n","Group\n","A    132\n","B    119\n","dtype: int64\n","\n","Model A Average Percentage Error: 1.4540%\n","Model B Average Percentage Error: 0.8334%\n","Directional Accuracy - Model A: 61.75%\n","Directional Accuracy - Model B: 67.33%\n","Model A Latency: 0.000160 sec\n","Model B Latency: 0.000061 sec\n","T-Test Results: T-Statistic = 5.5681, P-Value = 0.0000\n","\n","Model B shows a statistically significant improvement over Model A. Deploy Model B.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import yfinance as yf\n","import time\n","from scipy.stats import ttest_ind\n","\n","# Step 1: Fetch historical financial data for S&P 500\n","symbol = \"^GSPC\"\n","data = yf.download(symbol, start=\"2024-01-01\", end=\"2024-12-31\")\n","\n","# Flatten multi-index columns if present.\n","# With auto_adjust=True, the first level contains field names.\n","if isinstance(data.columns, pd.MultiIndex):\n","    data.columns = data.columns.get_level_values(0)\n","    data.columns.name = None  # Remove the name to avoid confusion\n","\n","# Use only closing prices for prediction analysis\n","data = data[['Close']]\n","data.dropna(inplace=True)\n","\n","# Ensure 'Close' is a Series\n","data[\"Close\"] = data[\"Close\"].squeeze()\n","\n","def simulate_predictions():\n","    # Step 2: Simulate Model A and Model B predictions with some noise\n","    np.random.seed(42)  # For reproducibility\n","    data[\"Prediction_A\"] = data[\"Close\"].apply(lambda x: x * (1 + np.random.normal(0, 0.02)))\n","    data[\"Prediction_B\"] = data[\"Close\"].apply(lambda x: x * (1 + np.random.normal(0, 0.01)))\n","\n","    # Preview predictions\n","    print(\"\\nPreview of predictions:\")\n","    print(data.head())\n","\n","def split_traffic():\n","    # Step 3: Split Traffic between two model groups (A and B)\n","    num_samples = len(data)\n","    data[\"Group\"] = np.random.choice([\"A\", \"B\"], size=num_samples, p=[0.5, 0.5])\n","    data[\"Forecast\"] = np.where(data[\"Group\"] == \"A\", data[\"Prediction_A\"], data[\"Prediction_B\"])\n","    # Ensure Series conversion if needed\n","    data[\"Forecast\"] = data[\"Forecast\"].squeeze()\n","    data[\"Close\"] = data[\"Close\"].squeeze()\n","\n","def run_experiment():\n","    # Step 4: Run the Experiment\n","    data[\"Error\"] = abs(data[\"Close\"] - data[\"Forecast\"])\n","    data[\"Percentage_Error\"] = (data[\"Error\"] / data[\"Close\"]) * 100\n","\n","    # Calculate directional accuracy based on trend differences\n","    data[\"Actual_Trend\"] = np.sign(data[\"Close\"].diff())\n","    data[\"Predicted_Trend_A\"] = np.sign(data[\"Prediction_A\"].diff())\n","    data[\"Predicted_Trend_B\"] = np.sign(data[\"Prediction_B\"].diff())\n","\n","    global accuracy_a, accuracy_b\n","    accuracy_a = (data[\"Predicted_Trend_A\"] == data[\"Actual_Trend\"]).mean() * 100\n","    accuracy_b = (data[\"Predicted_Trend_B\"] == data[\"Actual_Trend\"]).mean() * 100\n","\n","    # Simulate latency measurements for each model\n","    global latency_a, latency_b\n","    start_time_a = time.time()\n","    _ = data[\"Prediction_A\"].mean()\n","    latency_a = time.time() - start_time_a\n","\n","    start_time_b = time.time()\n","    _ = data[\"Prediction_B\"].mean()\n","    latency_b = time.time() - start_time_b\n","\n","def analyze_results():\n","    # Step 5: Analyze the Results using a t-test for the percentage error difference\n","    global errors_a, errors_b\n","    errors_a = data[data[\"Group\"] == \"A\"][\"Percentage_Error\"]\n","    errors_b = data[data[\"Group\"] == \"B\"][\"Percentage_Error\"]\n","\n","    global t_stat, p_value\n","    t_stat, p_value = ttest_ind(errors_a, errors_b, equal_var=False)\n","\n","def print_results():\n","    # Step 6: Print and Interpret the Results\n","    print(\"\\nGroup Sizes:\")\n","    print(data.groupby(\"Group\").size())\n","\n","    print(f\"\\nModel A Average Percentage Error: {errors_a.mean():.4f}%\")\n","    print(f\"Model B Average Percentage Error: {errors_b.mean():.4f}%\")\n","    print(f\"Directional Accuracy - Model A: {accuracy_a:.2f}%\")\n","    print(f\"Directional Accuracy - Model B: {accuracy_b:.2f}%\")\n","    print(f\"Model A Latency: {latency_a:.6f} sec\")\n","    print(f\"Model B Latency: {latency_b:.6f} sec\")\n","    print(f\"T-Test Results: T-Statistic = {t_stat:.4f}, P-Value = {p_value:.4f}\")\n","\n","    if p_value < 0.05:\n","        print(\"\\nModel B shows a statistically significant improvement over Model A. Deploy Model B.\")\n","    else:\n","        print(\"\\nNo significant difference between Model A and Model B. Further improvements are needed.\")\n","\n","# Execute the steps\n","simulate_predictions()\n","split_traffic()\n","run_experiment()\n","analyze_results()\n","print_results()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"zDLqLWQDslKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VgOQpFo5LqDK"},"execution_count":null,"outputs":[]}]}